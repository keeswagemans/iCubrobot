{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df683352-0bc1-435e-bf11-2d73cb8e3345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T08:49:26.011012Z",
     "iopub.status.busy": "2023-01-12T08:49:26.010456Z",
     "iopub.status.idle": "2023-01-12T08:49:37.594187Z",
     "shell.execute_reply": "2023-01-12T08:49:37.593164Z",
     "shell.execute_reply.started": "2023-01-12T08:49:26.010900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import layers, regularizers\n",
    "# from keras_tuner.tuners import RandomSearch\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow import keras \n",
    "!pip install -q -U keras-tuner \n",
    "import keras_tuner \n",
    "from keras_tuner import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f68bb324-5a9e-4e91-a94f-ec621846210b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T20:28:56.584540Z",
     "iopub.status.busy": "2023-01-11T20:28:56.584065Z",
     "iopub.status.idle": "2023-01-11T20:28:57.187656Z",
     "shell.execute_reply": "2023-01-11T20:28:57.186883Z",
     "shell.execute_reply.started": "2023-01-11T20:28:56.584514Z"
    }
   },
   "outputs": [],
   "source": [
    " # Loading pickles \n",
    "\n",
    "def load_color_inputs():\n",
    "    X_train_left = pickle.load(open('X_train_left.pkl', \"rb\"))\n",
    "    X_val_left = pickle.load(open('X_val_left.pkl', \"rb\"))\n",
    "    X_test_left = pickle.load(open('X_test_left.pkl', \"rb\"))\n",
    "    return X_train_left, X_val_left, X_test_left\n",
    "\n",
    "X_train_left, X_val_left, X_test_left = load_color_inputs()\n",
    "\n",
    "def load_outputs():\n",
    "    Y_train_left = pickle.load(open('Y_train_left.pkl', \"rb\"))\n",
    "    Y_val_left = pickle.load(open('Y_val_left.pkl', \"rb\"))\n",
    "    Y_test_left = pickle.load(open('Y_test_left.pkl', \"rb\"))\n",
    "    return Y_train_left, Y_val_left, Y_test_left\n",
    "\n",
    "Y_train_left, Y_val_left, Y_test_left = load_outputs()\n",
    "\n",
    "Y_train_left = np.argmax(Y_train_left, axis=-1)\n",
    "Y_val_left = np.argmax(Y_val_left, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c74ca87-1247-4ff0-a1e0-4a6a0dfbef92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T20:29:05.255425Z",
     "iopub.status.busy": "2023-01-11T20:29:05.255139Z",
     "iopub.status.idle": "2023-01-11T20:29:07.930460Z",
     "shell.execute_reply": "2023-01-11T20:29:07.929606Z",
     "shell.execute_reply.started": "2023-01-11T20:29:05.255404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8820,)\n",
      "INFO:tensorflow:Reloading Oracle from existing project ./untitled_project/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from ./untitled_project/tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 10\n",
      "layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 4, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "act_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid'], 'ordered': False}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "act_1 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "act_2 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid'], 'ordered': False}\n",
      "units_3 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "act_3 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid'], 'ordered': False}\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in ./untitled_project\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7f94e4074b80>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "units_0: 160\n",
      "act_0: relu\n",
      "units_1: 192\n",
      "act_1: relu\n",
      "learning_rate: 0.0001\n",
      "units_2: 320\n",
      "act_2: relu\n",
      "units_3: 352\n",
      "act_3: sigmoid\n",
      "Score: 0.9949206312497457\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "units_0: 96\n",
      "act_0: sigmoid\n",
      "units_1: 32\n",
      "act_1: sigmoid\n",
      "learning_rate: 0.0001\n",
      "units_2: 288\n",
      "act_2: relu\n",
      "Score: 0.9933333396911621\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "units_0: 416\n",
      "act_0: sigmoid\n",
      "units_1: 256\n",
      "act_1: sigmoid\n",
      "learning_rate: 0.01\n",
      "units_2: 32\n",
      "act_2: sigmoid\n",
      "Score: 0.004761904943734407\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "units_0: 448\n",
      "act_0: relu\n",
      "units_1: 352\n",
      "act_1: relu\n",
      "learning_rate: 0.01\n",
      "units_2: 32\n",
      "act_2: relu\n",
      "Score: 0.004761904943734407\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 4\n",
      "units_0: 416\n",
      "act_0: sigmoid\n",
      "units_1: 160\n",
      "act_1: sigmoid\n",
      "learning_rate: 0.001\n",
      "units_2: 384\n",
      "act_2: sigmoid\n",
      "units_3: 32\n",
      "act_3: relu\n",
      "Score: 0.004761904943734407\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Received incompatible tensor with shape (5, 5, 3, 32) when attempting to restore variable with shape (3, 3, 3, 32) and name layer_with_weights-0/kernel/.ATTRIBUTES/VARIABLE_VALUE.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m tuner\u001b[38;5;241m.\u001b[39mresults_summary()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Get the top 2 models.\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m best_model \u001b[38;5;241m=\u001b[39m models[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Build the model.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Needed for `Sequential` without specified `input_shape`.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/engine/tuner.py:374\u001b[0m, in \u001b[0;36mTuner.get_best_models\u001b[0;34m(self, num_models)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the tuner's objective.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03mThe models are loaded with the weights corresponding to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    List of trained model instances sorted from the best to the worst.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# Method only exists in this class for the docstring override.\u001b[39;00m\n\u001b[0;32m--> 374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTuner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/engine/base_tuner.py:296\u001b[0m, in \u001b[0;36mBaseTuner.get_best_models\u001b[0;34m(self, num_models)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    295\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_best_trials(num_models)\n\u001b[0;32m--> 296\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model(trial) \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m best_trials]\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/engine/base_tuner.py:296\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    295\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_best_trials(num_models)\n\u001b[0;32m--> 296\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m best_trials]\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/engine/tuner.py:305\u001b[0m, in \u001b[0;36mTuner.load_model\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# Reload best checkpoint.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Only load weights to avoid loading `custom_objects`.\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m maybe_distribute(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution_strategy):\n\u001b[0;32m--> 305\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_checkpoint_fname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/saving/saveable_object_util.py:133\u001b[0m, in \u001b[0;36mResourceVariableSaveable.restore\u001b[0;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[1;32m    130\u001b[0m   assigned_variable \u001b[38;5;241m=\u001b[39m resource_variable_ops\u001b[38;5;241m.\u001b[39mshape_safe_assign_variable_handle(\n\u001b[1;32m    131\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_op, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_shape, restored_tensor)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 133\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    134\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived incompatible tensor with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrestored_tensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen attempting to restore variable with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m assigned_variable\n",
      "\u001b[0;31mValueError\u001b[0m: Received incompatible tensor with shape (5, 5, 3, 32) when attempting to restore variable with shape (3, 3, 3, 32) and name layer_with_weights-0/kernel/.ATTRIBUTES/VARIABLE_VALUE."
     ]
    }
   ],
   "source": [
    " print(Y_train_left.shape) \n",
    "\n",
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    \n",
    "    for i in range(hp.Int('layers', 2, 4)): # Searching through for 2, 3 and 4 hidden layers\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=hp.Int('units_' + str(i), 32, 512, step=32), # Searching for optimal amount of nodes per hidden layer from 32 to 512 with step size of 32\n",
    "            activation=hp.Choice('act_' + str(i), ['relu', 'sigmoid']))) # Searching for optimal activation method\n",
    "    model.add(tf.keras.layers.Dense(210, activation='softmax')) # Output layer is kept out of the for loop because that is fixed\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate',\n",
    "                     values=[1e-2, 1e-3, 1e-4])), # Learning Rate of 0.01, 0.001 and 0.0001\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy', # Objective is to maximize validation accuracy\n",
    "    max_trials=5, # Trial 5 times\n",
    "    executions_per_trial=3,\n",
    "    overwrite=False, \n",
    "    )\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(X_train_left, Y_train_left, \n",
    "             epochs=50, \n",
    "             validation_data=(X_val_left, Y_val_left))\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "# Build the model.\n",
    "# Needed for `Sequential` without specified `input_shape`.\n",
    "CNN_left_2 = best_model.build(input_shape=(64, 64, 3))\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c780e2d1-ec7b-4400-8dc9-37d5cea3cff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-11T20:29:11.043011Z",
     "iopub.status.busy": "2023-01-11T20:29:11.042726Z",
     "iopub.status.idle": "2023-01-11T20:29:11.062791Z",
     "shell.execute_reply": "2023-01-11T20:29:11.061837Z",
     "shell.execute_reply.started": "2023-01-11T20:29:11.042989Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbest_model\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNN_left_2\u001b[39m\u001b[38;5;124m'\u001b[39m, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical \n\u001b[1;32m      5\u001b[0m Y_train_left \u001b[38;5;241m=\u001b[39m to_categorical(Y_train_left, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "best_model.save('CNN_left_2', save_format='h5') \n",
    "\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "Y_train_left = to_categorical(Y_train_left, dtype='float32') \n",
    "Y_val_left = to_categorical(Y_val_left, dtype='float32') \n",
    "Y_test_left = to_categorical(Y_test_left, dtype='float32') \n",
    "\n",
    "\n",
    "# Running model on training data \n",
    "best_model.compile(optimizer='Adam',\n",
    "                   loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                   metrics=['accuracy']) \n",
    "\n",
    "history = best_model.fit(X_train_left, Y_train_left, epochs=20, batch_size=64, validation_data=(X_val_left, Y_val_left))\n",
    "\n",
    "# Retrieving loss function \n",
    "\n",
    "def summarize_diagnostics(history):\n",
    "    # loss\n",
    "    plt.subplot(211)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='yellow', label='validation')\n",
    "\n",
    "    # accuracy\n",
    "    plt.subplot(212)\n",
    "    plt.title('Accuracy', y=-0.4)\n",
    "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_accuracy'], color='yellow', label='validation')\n",
    "    plt.legend(['training', 'validation'])\n",
    "    plt.show()\n",
    "\n",
    "summarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4c97ba-aed6-4b40-9c2a-5fae9cfad250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T08:59:00.868053Z",
     "iopub.status.busy": "2023-01-12T08:59:00.867556Z",
     "iopub.status.idle": "2023-01-12T08:59:11.513799Z",
     "shell.execute_reply": "2023-01-12T08:59:11.511485Z",
     "shell.execute_reply.started": "2023-01-12T08:59:00.868016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 08:59:11.360085: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 36.91MiB (rounded to 38707200)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-01-12 08:59:11.360708: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ***********xx**********xxxxx***********xxx______________***************_____________________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 85>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNN_left_2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Loading model\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# loss, accuracy = best_model.evaluate(X_test_left, Y_test_left, verbose=0)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# # Confusion Matrix for Test Data\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m predictions_test_left \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_left\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m pred_test_labels_left \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions_test_left, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# CM2_1 = confusion_matrix(Y_test_left, pred_test_labels_left, labels = np.arange(0,70))\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# ax = plt.axes()\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# sbn.heatmap(CM2_1, annot=False,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# plt.yticks(ticks=np.arange(0,70,10), labels=np.arange(140,210,10))\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "import itertools\n",
    "\n",
    "\n",
    "# Loading data\n",
    "def load_images():\n",
    "    X_train_left = pickle.load(open('X_train_left.pkl', 'rb'))\n",
    "    X_val_left = pickle.load(open('X_val_left.pkl', 'rb'))\n",
    "    X_test_left = pickle.load(open('X_test_left.pkl', 'rb'))\n",
    "    return X_train_left, X_val_left, X_test_left\n",
    "\n",
    "X_train_left, X_val_left, X_test_left = load_images()\n",
    "\n",
    "def load_labels():\n",
    "    Y_train_left = pickle.load(open('Y_train_left.pkl', 'rb'))\n",
    "    Y_val_left = pickle.load(open('Y_val_left.pkl', 'rb'))\n",
    "    Y_test_left = pickle.load(open('Y_test_left.pkl', 'rb'))\n",
    "    return Y_train_left, Y_val_left, Y_test_left\n",
    "\n",
    "Y_train_left, Y_val_left, Y_test_left = load_labels()\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('CNN_left_2')\n",
    "\n",
    "\n",
    "# Loading model\n",
    "\n",
    "# loss, accuracy = best_model.evaluate(X_test_left, Y_test_left, verbose=0)\n",
    "# print(loss, accuracy)\n",
    "\n",
    "# # Confusion Matrices for Validation Data\n",
    "\n",
    "# # Make label from one-hot encoding for confusion matrices\n",
    "# Y_train_left = np.argmax(Y_train_left, axis=1)\n",
    "# Y_val_left = np.argmax(Y_val_left, axis=1)\n",
    "# Y_test_left = np. argmax(Y_test_left, axis=1)\n",
    "\n",
    "\n",
    "# predictions_val_left = best_model.predict(X_val_left)\n",
    "# pred_val_labels_left = np.argmax(predictions_val_left, axis=1)\n",
    "\n",
    "# CM1_1 = confusion_matrix(Y_val_left, pred_val_labels_left, labels=np.arange(0,70))\n",
    "# ax = plt.axes()\n",
    "# sbn.heatmap(CM1_1, annot=False,\n",
    "#             annot_kws = {\"size\":10},\n",
    "#             xticklabels = np.arange(0,70,10),\n",
    "#             yticklabels = np.arange(0,70,10), ax = ax),\n",
    "# ax.set_title(\"CM for Classes 0 - 70 of Validation Data\")\n",
    "# plt.xticks(ticks=np.arange(0,70,10), labels=np.arange(0,70,10))\n",
    "# plt.yticks(ticks=np.arange(0,70,10), labels=np.arange(0,70,10))\n",
    "# plt.show()\n",
    "\n",
    "# CM1_2 = confusion_matrix(Y_val_left, pred_val_labels_left, labels=np.arange(70,140))\n",
    "# ax = plt.axes()\n",
    "# sbn.heatmap(CM1_2, annot=False,\n",
    "#             annot_kws = {\"size\":10},\n",
    "#             xticklabels = np.arange(70,140,10),\n",
    "#             yticklabels = np.arange(70,140,10), ax=ax),\n",
    "# ax.set_title(\"CM for Classes 70 - 140 of Validation Data\")\n",
    "# plt.xticks(ticks=np.arange(0,70,10), labels=np.arange(70,140,10))\n",
    "# plt.yticks(ticks=np.arange(0,70,10), labels=np.arange(70,140,10))\n",
    "# plt.show()\n",
    "\n",
    "# CM1_3 = confusion_matrix(Y_val_left, pred_val_labels_left, labels = np.arange(140, 210))\n",
    "# ax = plt.axes()\n",
    "# sbn.heatmap(CM1_3, annot=False,\n",
    "#             annot_kws = {\"size\":10},\n",
    "#             xticklabels = np.arange(140,210,10),\n",
    "#             yticklabels = np.arange(140,210,10), ax = ax),\n",
    "# ax.set_title(\"CM for Classes 140 - 210 of Validation Data\")\n",
    "# plt.xticks(ticks=np.arange(0,70,10), labels=np.arange(140,210,10))\n",
    "# plt.yticks(ticks=np.arange(0,70,10), labels=np.arange(140,210,10))\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # Confusion Matrix for Test Data\n",
    "\n",
    "predictions_test_left = best_model.predict(X_test_left)\n",
    "pred_test_labels_left = np.argmax(predictions_test_left, axis=1)\n",
    "\n",
    "# CM2_1 = confusion_matrix(Y_test_left, pred_test_labels_left, labels = np.arange(0,70))\n",
    "# ax = plt.axes()\n",
    "# sbn.heatmap(CM2_1, annot=False,\n",
    "#             annot_kws={\"size\":10},\n",
    "#             xticklabels=np.arange(0,70,10),\n",
    "#             yticklabels=np.arange(0,70,10), ax=ax)\n",
    "# ax.set_title(\"CM for Classes 0 - 70 of Test Data\")\n",
    "# plt.xticks(ticks=np.arange(0,70,10), labels=np.arange(0,70,10))\n",
    "# plt.yticks(ticks=np.arange(0,70,10), labels=np.arange(0,70,10))\n",
    "# plt.show()\n",
    "\n",
    "# CM2_2 = confusion_matrix(Y_test_left, pred_test_labels_left, labels = np.arange(70,140))\n",
    "# ax = plt.axes()\n",
    "# sbn.heatmap(CM2_2, annot=False,\n",
    "#             annot_kws={\"size\":10},\n",
    "#             xticklabels = np.arange(70,140,10),\n",
    "#             yticklabels = np.arange(70,140,10), ax=ax)\n",
    "# ax.set_title(\"CM for Classes 70 - 140 of Test Data\")\n",
    "# plt.xticks(ticks=np.arange(0,70,10), labels=np.arange(70,140,10))\n",
    "# plt.yticks(ticks=np.arange(0,70,10), labels=np.arange(70,140,10))\n",
    "# plt.show()\n",
    "\n",
    "# CM2_3 = confusion_matrix(Y_test_left, pred_test_labels_left, labels = np.arange(140,210))\n",
    "# ax = plt.axes()\n",
    "# sbn.heatmap(CM2_3, annot=False,\n",
    "#             annot_kws={\"size\":10},\n",
    "#             xticklabels = np.arange(140,210,10),\n",
    "#             yticklabels = np.arange(140,210,10), ax = ax)\n",
    "# ax.set_title(\"CM for Classes 140 - 210 of Test Data\")\n",
    "# plt.xticks(ticks=np.arange(0,70,10), labels=np.arange(140,210,10))\n",
    "# plt.yticks(ticks=np.arange(0,70,10), labels=np.arange(140,210,10))\n",
    "# plt.show()\n",
    "\n",
    "report_val = classification_report(Y_val_left, pred_val_labels_left)\n",
    "print(report_val)\n",
    "\n",
    "# # Classification Report for Test Data\n",
    "\n",
    "# report_test = classification_report(Y_test_left, pred_test_labels_left, digits=5, output_dict=True)\n",
    "# print(report_test)\n",
    "\n",
    "print(pred_labels_left[2730:2745])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
