{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4aed3dc-c2c1-4874-89fd-1896e0c38e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 11:21:56.572133: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 36.91MiB (rounded to 38707200)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-01-10 11:21:56.572276: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ********************xxxxxxxx******************************__________________________________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Loading model\u001b[39;00m\n\u001b[1;32m     29\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNN_left_2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Make label from one-hot encoding for confusion matrices\u001b[39;00m\n\u001b[1;32m     34\u001b[0m Y_train_left \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(Y_train_left, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "import itertools\n",
    "\n",
    "# Loading data\n",
    "def load_images():\n",
    "    X_train_left = pickle.load(open('X_train_left.pkl', 'rb'))\n",
    "    X_val_left = pickle.load(open('X_val_left.pkl', 'rb'))\n",
    "    X_test_left = pickle.load(open('X_test_left.pkl', 'rb'))\n",
    "    return X_train_left, X_val_left, X_test_left\n",
    "\n",
    "X_train_left, X_val_left, X_test_left = load_images()\n",
    "\n",
    "def load_labels():\n",
    "    Y_train_left = pickle.load(open('Y_train_left.pkl', 'rb'))\n",
    "    Y_val_left = pickle.load(open('Y_val_left.pkl', 'rb'))\n",
    "    Y_test_left = pickle.load(open('Y_test_left.pkl', 'rb'))\n",
    "    return Y_train_left, Y_val_left, Y_test_left\n",
    "\n",
    "Y_train_left, Y_val_left, Y_test_left = load_labels()\n",
    "\n",
    "# Loading model\n",
    "model = tf.keras.models.load_model('CNN_left_2')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_left, Y_test_left, verbose=2)\n",
    "\n",
    "# Make label from one-hot encoding for confusion matrices\n",
    "Y_train_left = np.argmax(Y_train_left, axis=1)\n",
    "Y_val_left = np.argmax(Y_val_left, axis=1)\n",
    "Y_test_left = np. argmax(Y_test_left, axis=1)\n",
    "\n",
    "# Confusion Matrices for Validation Data\n",
    "\n",
    "path = '/Volumes/Macintosh HD/Users/keeswagemans/Desktop/Thesis/iCub dataset/'\n",
    "objects = open(path + 'objects.txt')\n",
    "objects = list(objects)\n",
    "objects = [i.split('\\n', 1)[0] for i in objects]\n",
    "objects = [i.replace(' ', '_') for i in objects]\n",
    "\n",
    "predictions_val_left = model.predict(X_val_left)\n",
    "pred_val_labels_left = np.argmax(predictions_val_left, axis=1)\n",
    "\n",
    "CM1_1 = confusion_matrix(Y_val_left, pred_val_labels_left, labels=np.arange(0,70))\n",
    "ax = plt.axes()\n",
    "sbn.heatmap(CM1_1, annot=False,\n",
    "            annot_kws = {\"size\":10},\n",
    "            xticklabels = np.arange(0,70,10),\n",
    "            yticklabels = np.arange(0,70,10), ax = ax),\n",
    "ax.set_title(\"CM for Classes 0 - 70 of Validation Data\")\n",
    "plt.xticks(ticks=np.arange(0,70,10), labels=np.arange(0,70,10))\n",
    "plt.yticks(ticks=np.arange(0,70,10), labels=np.arange(0,70,10))\n",
    "plt.show()\n",
    "\n",
    "CM1_2 = confusion_matrix(Y_val_left, pred_val_labels_left, labels=np.arange(70,140))\n",
    "ax = plt.axes()\n",
    "sbn.heatmap(CM1_2, annot=False,\n",
    "            annot_kws = {\"size\":10},\n",
    "            xticklabels = np.arange(70,140,10),\n",
    "            yticklabels = np.arange(70,140,10), ax=ax),\n",
    "ax.set_title(\"CM for Classes 70 - 140 of Validation Data\")\n",
    "plt.xticks(ticks=np.arange(0,70,10), labels=np.arange(70,140,10))\n",
    "plt.yticks(ticks=np.arange(0,70,10), labels=np.arange(70,140,10))\n",
    "plt.show()\n",
    "\n",
    "CM1_3 = confusion_matrix(Y_val_left, pred_val_labels_left, labels = np.arange(140, 210))\n",
    "ax = plt.axes()\n",
    "sbn.heatmap(CM1_3, annot=False,\n",
    "            annot_kws = {\"size\":10},\n",
    "            xticklabels = np.arange(140,210,10),\n",
    "            yticklabels = np.arange(140,210,10), ax = ax),\n",
    "ax.set_title(\"CM for Classes 140 - 210 of Validation Data\")\n",
    "plt.xticks(ticks=np.arange(0,70,10), labels=np.arange(140,210,10))\n",
    "plt.yticks(ticks=np.arange(0,70,10), labels=np.arange(140,210,10))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Confusion Matrix for Test Data\n",
    "\n",
    "predictions_test_left = model.predict(X_test_left)\n",
    "pred_test_labels_left = np.argmax(predictions_test_left, axis=1)\n",
    "\n",
    "CM2_1 = confusion_matrix(Y_test_left, pred_test_labels_left, labels = np.arange(0,70))\n",
    "ax = plt.axes()\n",
    "sbn.heatmap(CM2_1, annot=False,\n",
    "            annot_kws={\"size\":10},\n",
    "            xticklabels=np.arange(0,70,10),\n",
    "            yticklabels=np.arange(0,70,10), ax=ax)\n",
    "ax.set_title(\"CM for Classes 0 - 70 of Test Data\")\n",
    "plt.xticks(ticks=np.arange(0,70,10), labels=np.arange(0,70,10))\n",
    "plt.yticks(ticks=np.arange(0,70,10), labels=np.arange(0,70,10))\n",
    "plt.show()\n",
    "\n",
    "CM2_2 = confusion_matrix(Y_test_left, pred_test_labels_left, labels = np.arange(70,140))\n",
    "ax = plt.axes()\n",
    "sbn.heatmap(CM2_2, annot=False,\n",
    "            annot_kws={\"size\":10},\n",
    "            xticklabels = np.arange(70,140,10),\n",
    "            yticklabels = np.arange(70,140,10), ax=ax)\n",
    "ax.set_title(\"CM for Classes 70 - 140 of Test Data\")\n",
    "plt.xticks(ticks=np.arange(0,70,10), labels=np.arange(70,140,10))\n",
    "plt.yticks(ticks=np.arange(0,70,10), labels=np.arange(70,140,10))\n",
    "plt.show()\n",
    "\n",
    "CM2_3 = confusion_matrix(Y_test_left, pred_test_labels_left, labels = np.arange(140,210))\n",
    "ax = plt.axes()\n",
    "sbn.heatmap(CM2_3, annot=False,\n",
    "            annot_kws={\"size\":10},\n",
    "            xticklabels = np.arange(140,210,10),\n",
    "            yticklabels = np.arange(140,210,10), ax = ax)\n",
    "ax.set_title(\"CM for Classes 140 - 210 of Test Data\")\n",
    "plt.xticks(ticks=np.arange(0,70,10), labels=np.arange(140,210,10))\n",
    "plt.yticks(ticks=np.arange(0,70,10), labels=np.arange(140,210,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41815bf-6e49-48d8-a8d4-c2f07b4d1625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
